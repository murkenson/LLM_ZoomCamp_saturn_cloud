{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91c1d4f-fea9-4838-b6d6-92e3557dbcad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:12:41.323700Z",
     "iopub.status.busy": "2024-07-08T18:12:41.323321Z",
     "iopub.status.idle": "2024-07-08T18:12:41.330639Z",
     "shell.execute_reply": "2024-07-08T18:12:41.329838Z",
     "shell.execute_reply.started": "2024-07-08T18:12:41.323667Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb9bd2d-3f9e-4774-acb4-479074ea8cf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:12:42.410490Z",
     "iopub.status.busy": "2024-07-08T18:12:42.410107Z",
     "iopub.status.idle": "2024-07-08T18:12:43.743645Z",
     "shell.execute_reply": "2024-07-08T18:12:43.742891Z",
     "shell.execute_reply.started": "2024-07-08T18:12:42.410467Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-08 18:12:43--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-08 18:12:43 (83.3 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d98e6ab-f7af-4fef-8e95-b3ad1eec49ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:12:45.452781Z",
     "iopub.status.busy": "2024-07-08T18:12:45.452249Z",
     "iopub.status.idle": "2024-07-08T18:12:45.658951Z",
     "shell.execute_reply": "2024-07-08T18:12:45.658130Z",
     "shell.execute_reply.started": "2024-07-08T18:12:45.452745Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f5753493940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dda8e1a-ded2-48a4-bcac-7ec0e8f8f0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:12:46.843586Z",
     "iopub.status.busy": "2024-07-08T18:12:46.843209Z",
     "iopub.status.idle": "2024-07-08T18:12:46.848642Z",
     "shell.execute_reply": "2024-07-08T18:12:46.847555Z",
     "shell.execute_reply.started": "2024-07-08T18:12:46.843560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae922ca-e2d6-4c2b-9dd2-037105d8b446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:12:48.633838Z",
     "iopub.status.busy": "2024-07-08T18:12:48.633444Z",
     "iopub.status.idle": "2024-07-08T18:12:48.637862Z",
     "shell.execute_reply": "2024-07-08T18:12:48.636976Z",
     "shell.execute_reply.started": "2024-07-08T18:12:48.633813Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dfbed3a-f311-4f3f-8039-5ebb6b1e5796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:12:49.763176Z",
     "iopub.status.busy": "2024-07-08T18:12:49.762777Z",
     "iopub.status.idle": "2024-07-08T18:12:50.493173Z",
     "shell.execute_reply": "2024-07-08T18:12:50.492351Z",
     "shell.execute_reply.started": "2024-07-08T18:12:49.763142Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  8 18:12:50 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56a64c1-dce1-443d-afc6-bcc04f19797f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:52:26.516785Z",
     "iopub.status.busy": "2024-07-08T17:52:26.516365Z",
     "iopub.status.idle": "2024-07-08T17:52:27.135060Z",
     "shell.execute_reply": "2024-07-08T17:52:27.134247Z",
     "shell.execute_reply.started": "2024-07-08T17:52:26.516756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         100G   36G   65G  36% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\n",
      "/dev/nvme0n1p1  100G   36G   65G  36% /run\n",
      "tmpfs            14G     0   14G   0% /dev/shm\n",
      "/dev/nvme2n1    2.0G  564K  1.9G   1% /home/jovyan\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\n",
      "tmpfs           7.7G  4.6M  7.7G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f73aea8-22b5-48b0-a128-d9be22dfda2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:13:57.024919Z",
     "iopub.status.busy": "2024-07-08T18:13:57.024501Z",
     "iopub.status.idle": "2024-07-08T18:14:00.941741Z",
     "shell.execute_reply": "2024-07-08T18:14:00.940974Z",
     "shell.execute_reply.started": "2024-07-08T18:13:57.024891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f575318c310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b40d2fb-a52f-4827-abaf-ef5b9eeeda8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:14:07.501829Z",
     "iopub.status.busy": "2024-07-08T18:14:07.501309Z",
     "iopub.status.idle": "2024-07-08T18:15:01.214054Z",
     "shell.execute_reply": "2024-07-08T18:15:01.213241Z",
     "shell.execute_reply.started": "2024-07-08T18:14:07.501800Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e37ef5749824792abbe0017f0992c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c6c43606ba47d083a294ba1ccaa9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9cb297651347bb83259e8d3975fbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c3e5bff6f941c9ab92b884b0d53726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787ec4190733434dac1f0852fb70ca56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2f5bb53acb4c8788e555b753023b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5160c124816747c79ac23c37ee60f35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f901757a4fc34418af94282c7575b579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c65e98fa444860afe20080323f8833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565e54a40c43459c9852ca41aad08d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a98cc92a4e4f278ce624fa087f765f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6269e0084f9346a0a998c3bb475a5e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1c41418e364d2da67e21186b71c49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b2b2d096194aa28c1984e6d11e227f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\", \n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70515d0c-49a0-4d6c-9915-a4d7fc1231bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:15:06.510422Z",
     "iopub.status.busy": "2024-07-08T18:15:06.510029Z",
     "iopub.status.idle": "2024-07-08T18:15:06.514248Z",
     "shell.execute_reply": "2024-07-08T18:15:06.513454Z",
     "shell.execute_reply.started": "2024-07-08T18:15:06.510397Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a5a1af0-9e62-4559-8f6d-219717f99123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:15:16.581497Z",
     "iopub.status.busy": "2024-07-08T18:15:16.581105Z",
     "iopub.status.idle": "2024-07-08T18:15:16.587460Z",
     "shell.execute_reply": "2024-07-08T18:15:16.586652Z",
     "shell.execute_reply.started": "2024-07-08T18:15:16.581474Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": 500,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": 0.0,\n",
    "        \"do_sample\": False,\n",
    "    }\n",
    "\n",
    "    output = pipe(messages, **generation_args)\n",
    "    return output[0]['generated_text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bc304e2-8d47-478e-851b-a836e15b6b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:15:26.254736Z",
     "iopub.status.busy": "2024-07-08T18:15:26.254377Z",
     "iopub.status.idle": "2024-07-08T18:15:33.133375Z",
     "shell.execute_reply": "2024-07-08T18:15:33.132560Z",
     "shell.execute_reply.started": "2024-07-08T18:15:26.254711Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You can still join the course even if you discover it after the start date. You are eligible to submit the homeworks, but remember to meet the deadlines for the final projects. You can also follow the course materials at your own pace after it finishes, and start working on your final capstone project.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"I just discovered the course. Can I still join it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c6b959-6d77-4c34-9044-8e67bde79d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T18:15:51.370779Z",
     "iopub.status.busy": "2024-07-08T18:15:51.370287Z",
     "iopub.status.idle": "2024-07-08T18:15:58.686823Z",
     "shell.execute_reply": "2024-07-08T18:15:58.685746Z",
     "shell.execute_reply.started": "2024-07-08T18:15:51.370751Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the provided context does not directly answer the question about whether your friend can join the course. However, based on the information given, you can suggest that your friend can join the course by registering before the start date using the provided link. Additionally, you can encourage your friend to install the necessary dependencies and familiarize themselves with the prerequisites and syllabus.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"I just discovered the course. Can my friend join it?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
